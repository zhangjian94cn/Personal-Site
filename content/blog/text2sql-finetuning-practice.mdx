---
title: "江苏移动数智助手 Text2SQL 大模型微调实践"
date: "2024-08-03"
tags: ["LLM", "Text2SQL", "微调", "LoRA"]
draft: false
summary: "分享在数智助手项目中进行 Text2SQL 微调的实践经验，包括问题分析、训练数据准备、LoRA 微调过程及效果评估。"
authors: ["default"]
---

> "随着人工智能技术的迅猛发展，企业在数据处理和分析方面的需求也日益增长。为了更高效地从海量数据中提取有用信息，我们在数智助手中进行了Text2SQL微调实践。这不仅提高了数据查询的效率，还大幅提升了用户体验。"

## 问题分析

Text2SQL也称NL2SQL，指用自然语言向LLM提问，推理生成结构化SQL语句的过程。

随着大语言模型的迅猛演进，通过LLM将自然语言表达的用户需求转化为SQL查询指令，已确立为解决复杂数据检索问题的首选方案。我们利用海量数据对大模型进行微调，从而增强其在新场景下的适应性和准确性，最终形成：**用户问题-SQL命令生成-SQL查询结果返回-查询结果总结输出的完整闭环**，实现可靠、准确的问答流程。

在项目早期未引入Text2SQL时，针对用户套餐查询的需求，我们基于单纯RAG语义向量匹配和基座大模型能力，无法实现对用户问题的精准回答。

### Text2SQL大模型现存问题

在实践过程中，我们发现目前的Text2SQL中存在的一些主要问题包括：

**(1) 输出幻觉（Hallucination）**：LLM在生成SQL语句时会生成一些看似合理，但实际与输入文本无关或错误的查询，这可能是由于模型尚未充分学习到数据库的信息和SQL逻辑，导致在推理阶段产生误导性的输出。例如，当用户提问："比语音翻倍包更经济的套餐有哪些？"，生成的SQL命令为：

```sql
"SELECT * FROM database WHERE money < 50;"
```

大模型直接认为"语音翻倍包"的价格为50元，并以此输出SQL语句，导致查询结果出错。

**(2) 答案稳定性**：模型生成答案不够稳定，偶尔需要多次提问才能找到最优答案。例如，用户多次提问"请问流量超过3000MB有几种套餐"，得到的回答会出现以下几种情况：

```sql
SELECT COUNT(*) FROM database WHERE en_names LIKE %'流量超过3000MB'%;
SELECT COUNT(*) FROM database WHERE en_broadband > 3;
SELECT COUNT(*) FROM database WHERE en_broadband > 3000;
```

在多次提问的过程中，出现了语义理解不清（将"流量超过3000MB"作为套餐名）、单位换算出错（MB转换成GB）的情况，暴露出大模型稳定性不强的问题。

### 优化方法

为了解决这些模型问题，我们考虑了**Prompt Engineering（提示工程）**、**Fine-tuning（模型微调）**等方式对模型进行优化。

**(1) Prompt Engineering（提示工程）**能够通过设计特定的提示词或句子，引导模型生成更贴合用户意图的输出。在处理SQL查询时，向模型注入特定领域的知识，比如SQL规范、数据库架构以及注意单位转换等额外要求，能够显著提升模型对于SQL语句结构和逻辑的理解能力。

**(2) Fine-tuning（模型微调）**是一种先进的机器学习技术，旨在针对预训练模型进行定制化调整，使其更加契合特定应用场景的需求。LoRA微调通过将模型的部分权重矩阵分解为两个低秩矩阵，只更新这两个小矩阵的参数来实现微调，**从而减少计算资源和内存占用**。

## 微调训练数据准备

### 生成方法

(1) 提取关键属性信息，对业务知识提取关键属性及对应的信息。可抽取的关键属性为：

```
套餐名称：{names}
套餐价格：{money}
套餐流量：{GB}
可通话时长：{duration}
套餐上线年份：{online_years}
```

(2) 构建常见的用户问题与sql命令语料对，通过抽象化用户可能提问的问题，并进行对应的同义词替换，生成大量训练样本

**示例1**：查询128元的套餐

```sql
SELECT * FROM {table_name} WHERE money = {money};
```

**示例2**：降档流量套餐到60G

```sql
SELECT * FROM {table_name} WHERE GB = {GB};
```

(3) 训练语料对保存为json格式

```json
{
  "user": {"升级到41GB流量的套餐，有什么建议"},
  "assistant": {"SELECT * FROM database WHERE GB = 41000;"}
}
```

### 生成规模

共生成**15w条语料对**，包括正向语料和反向语料：

- **正向语料**（用户输入能够生成sql命令）：
  - **直接查询类**：用户直接询问明确的套餐名称、价格，生成**5w条样本**
  - **数字比较类**：用户希望找到更优惠、更多流量的套餐，生成**5w条样本**

- **反向语料**（用户输入无法生成sql命令）：生成**5w条样本**

## 微调过程

1. 所需资源：**GPU：NVIDIA A100-SXM4-40GB x2**；**微调模型：QWen-7b-chat**

2. 微调过程
   - **训练时长**：大约3.75小时

我们对微调后的模型进行测试，用户问题与SQL语句的转换正确率可达**98.56%**，达到了生产上线的标准。当我们将微调模型部署后，回答的套餐信息已明显扩充，并且从用户角度考虑了短期和长期两种情况，向用户提供了更全面、更可靠的答案。

## 未来展望

随着大模型技术的日新月异，Text2SQL技术也在以惊人的速度不断发展。目前所采用的优化手段，虽然在现阶段可能有效，但随着大模型能力的持续提升，这些手段很可能会逐渐显得过时。

一方面，我们不能神话大型语言模型（LLM）的能力，给予其过高的期望。另一方面，我们也不能因高估工程实现的难度而望而生畏。只有一步一个脚印，踏踏实实地解决工程实践中的每一个问题，才能最终将Text2SQL技术推向成熟的生产阶段。
