---
title: "My Interview Documentation"
date: "2023-02-08"
tags: []
draft: false
summary: "My Interview Documentation"
authors: ["default"]
---

# 自我介绍

## 参考资料

1. [机器学习](https://github.com/zhengjingwei/machine-learning-interview#2-1-6)
2. 深度学习
   1. https://github.com/Mikoto10032/DeepLearning
   2. https://github.com/ashishpatel26/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code
   3. https://github.com/janishar/mit-deep-learning-book-pdf
   4. https://github.com/roboticcam/machine-learning-notes
   5. https://github.com/d2l-ai/d2l-zh
   6. https://github.com/labmlai/annotated_deep_learning_paper_implementations
   7. https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap
   8. https://github.com/AMAI-GmbH/AI-Expert-Roadmap
   9. https://github.com/ChristosChristofidis/awesome-deep-learning
3. [文本分类](https://github.com/catqaq/OpenTextClassification)


### 报名

本科期间主要学习了包括高等数学，大学物理，几何与代数等基础课程，以及微机系统与接口，信号与系统，电子电路等专业课程。本科阶段绩点为年级前10%，后保研至南京大学。曾获得大学生数学建模竞赛国家二等奖与国际一等奖，以及多次校级竞赛获奖，曾于日本早稻田大学IPS学院国际联合学术报告会发表论文一篇，并至早稻田大学进行学术交流。

研究生期间的主要学习课程包括：矩阵论，软件工程实践，成像原理与图像工程等课程，期间认真学习相关课程并完成导师布置的的相关科研任务，研究生期间发表一篇SCI论文（SENSOR 202）并申请专利一份。获得阿里巴巴、网易等知名企业的SP Offer（较普通offer薪酬更高）


在英特尔，目前主要负责基于分布式的大语言模型（Large Language Model）预训练与微调，设计并搭建了基于Ray框架的预训练（pretrain）、有监督微调（SFT），抽象并实现数据预处理、模型定义与训练等模块，实现对 Llama、Dolly、Pythia 等大模型的支持，此外，搭建了一套基于大模型的垂直领域知识问答应用系统，参加天池 SMP 2023 ChatGLM 金融大模型挑战赛，2294 支队伍中复赛排名 13。此外，还曾负责梯度提升决策树推理优化，实现相对于 XGBoost 的 2 倍加速，获 2022 第四季度QPB+（共 18 人团队中最佳绩效）。


2020.6.29 ~ 2022.7.

在阿里核心部门淘系技术部，我负责为淘宝实现一套“商品的数字化方案”，我主要负责了“3D神经网络模型的手淘端上应用”与“鲁棒的3D神经网络模型重建”项目，完成了从算法设计，开发，测试到部署的一整套工作，算法也成功上线手淘。方案获得了22年淘宝双十一9大技术亮点之一等荣誉。基于产品应用中的实际问题，我进行算法创新，形成了两篇论文，分别被国际顶级会议CVPR，ECCV接受，我均为第一作者，技术受到了国际级认可。2022年，我晋升至高级算法工程师，并连续两年获得团队最高绩效。


## 个人简介

1. 问好，我是xx，读研经历
2. 加入阿里xx部门，做什么（重建系统，具体到我，上线手淘），荣誉（公司，论文，晋升，绩效）
3. 加入xx组，做什么（gbdt，提出了xx，实现xx），荣誉
4. 方法论（用处...），个人兴趣（...）

---

各位面试官好，我叫章坚。我本科毕业于东南大学的电子科学与技术专业，研究生毕业
于南京大学的电子与通信工程专业。读研期间，我的研究方向是：基于深度学习的3D视
觉理解与场景重建，其主要应用于智慧城市，自动驾驶等领域，同时我完成了一篇专利
与SCI期刊。

毕业后，我进入阿里核心部门淘系技术部，负责为淘宝实现一套“商品的数字化方案”
我完成了从人工智能算法设计，开发，测试到部署的一整套工作，算法也成功上线手淘。
方案获得了22年淘宝双十一9大技术亮点之一等荣誉。此外，基于产品应用中的实际问题，
我进行创新，形成了两篇论文，分别被国际顶级会议CVPR，ECCV接受，我均为第一作者，
技术受到了国际级认可。同年，我晋升至高级算法工程师，并连续两年获得团队最高绩效。

去年，我来到英特尔，加入了人工智能与分析团队，担任人工智能构架工程师一职，负责
人工智能大模型的训练、推理、优化与应用架构的工作。基于业内领先的云计算分布式框
架ray，实现了一整套自研的大模型训练与推理框架，期间我们与国外的团队紧密合作，共
同为intel训练自己的大语言模型。同时，我们还进一步构建了在金融垂直领域的大语言模
型应用，完成了从财报数据处理、多模态数据库构建、模型微调、数据检索等一系列工作，
最终实现了对上市公司信息的快速准确的回答，
作品也参加了天池的比赛，在全国2000多支队伍中获得了第13名的成绩。最后在工作期间，
我曾获得团队最佳绩效等荣誉。

简单总结下，在阿里，基于淘宝这样一个非常难得的数字化场景，我熟悉了一整套基于深度
学习的算法开发，优化以及部署流程，让我对人工智能有了非常深刻的认知，而阿里作为国
内顶尖的互联网公司，在企业文化、组织架构、团队合作、任务分配等方面上同样也让我受
益匪浅。

而在英特尔，作为国际一流的外企，我不仅获得了技术上的成长，实现了从算法开
发到人工智能系统整体架构的转变，更是熟悉了一套高效的人工智能项目开发与管理流程，
通过与国际各团队的合作，让我能接触到国外最先进的技术方案。此外，我也一直保持着对
技术的热情，不断学习并且提升自己。谢谢各位面试官



<!-- 从场景的数字化到商品的数字化，再到智能的分析与决策，我积累了产业数字化的算法经验，形成了一套自己的算法设计与开发方法论。这让我在面对实际问题时，不仅能够快速的找到解决方案，同时尽可能的从问题本质出发设计算法，从根本上保证算法在实际应用中的效果。同时，我也一直保持着对技术的热情，持续阅读最新技术的相关论文，从中学习算法设计的核心思想。谢谢~ -->


### 一些问题

我觉得要去强调：
1. 团队、项目的组织管理能力
2. 能够带来有很高应用价值的项目
3. 能够帮助团队快速跟进最新技术，将其进行实际应用

---

1. **为什么离开阿里，为什么离开英特尔来******
   1. 离开阿里：
      1. 组织结构上的频繁变动不利于长远发展，也很难将一件事情持续做下去并做好
      2. 感觉到互联网行业发展不像之前那样迅速，而芯片是当时的热点，因此想换个赛道
      3. 在英特尔做的是人工智能的架构，和我之前的工作内容区别比较大，想借此拓宽下自己的知识面
         同时也想体验下外企的公司文化、组织架构、任务分配方式
         因此，虽然当时网易给出的86w的offer，我仍然选择了intel
      4. 
   2. 离开英特尔：
      1. 家庭原因：
         因为工作在上海，所以需要长期奔波，在有了小孩之后希望能安定下来，希望能在****长期稳定发展
      2. 
      3. ****的核心业务在国内，相信发展空间是很大的，同时拥有海量的数据与计算资源，而我对算法应用部署的一整套流程都非常了解，基于******提供的“数据+算力”，我希望能够做一些有价值的人工智能应用，将人工智能应用到生活的方方面面

2. **在阿里学到了什么**
   
   我所在的部门是：

   1. 在阿里，我熟悉了一整套**基于深度学习算法的开发，优化以及部署流程**，让我对深度学习有了比较深刻的认识，包括：
      
      1）**如何对深度学习算法进行选型**，同一问题在不同的实际条件下，模型选择和使用方案都会有比较大的区别
      
      例如，在工业检测、自动驾驶等领域，其对模型的速度要求往往比较高，在模型的端上应用时，可以选择一些轻量化的模型架构，其次可以对模型进行量化、剪枝，同时为了避免这些模型性能出现较大下，往往需要做一些微调
      
      而如果模型是在云端部署的，算力资源比较丰富，那模型架构可以选择一些较深的网络，例如对图像视频分类以及检测的任务可以选择一些VIT的架构

      2）在淘宝，我**非常全面的实现了算法应用的整条链路**，包括：图像分割，位姿估计，3D重建，图像融合等模块，解决了多模块之间的依赖、调度等问题，迅速实现了Object Drawer项目的构建

      对于深度学习的基础算法，包括：检测、分类、分割等任务，在研究生的生涯中，我都有着实际使用的经验，在进入阿里工作后，面对商品数字化的业务需求，我能够基于这些成熟的基础算法模块，实现一个人工智能应用的完整搭建
      
      以图像分割为例，选取了当时效果最好的**U2Net网络**，然而其对于物体的**细节分割效果仍然难以达到实际应用标准**，对此，我们基于**信噪比**去除模糊图片，结合**深度估计**算法进一步提升了分割效果


   2. 在阿里，我不仅仅满足于调用开源代码，而是**深入深度学习算法的设计思想，去灵活的解决实际问题**
      
      我几乎每天都会阅读最新的论文，将优秀的算法思想纳入到自己解决问题的工具库中来，我刚进入工作时，淘宝想实现低成本高质量的商品数字化，例如使用手机拍摄一圈商品，就能得到商品的数字化模型，当时我基于可微渲染的一篇论文，将商品模型转化为一个小的神经网络，将其放到了淘宝的app中

      这中间遇到了很多问题，比如“模型推理太慢”，那么就利用**空间换时间**的思想，将模型结构拉平，大大提升了推理速度（接近1w倍），存储增大以后手机很难放的下，这时候我们利用**稀疏性**的思想，对纹理以及几何进行压缩，让每一个模型大小保证在5m以内，最终实现了手机端可用

      在这个过程中，我没有刻意追求创新，而是灵活的解决实际问题，最终我也将相关成果进行整理，发表了两篇顶级的人工智能论文，而且我都是第一作者，此外还有一篇专利，这也让我在阿里每年都是团队最好的绩效（375）

   3. 在阿里，我也熟悉了国内顶尖互联网公司的**企业文化、组织架构、团队合作、任务分配、绩效管理**等方面的内容。
      
      虽然阿里作为非常大的互联网公司，但是在一个小团队内部的效率还是非常不错的，尤其在新项目上有点类似于创业团队的氛围，大家能够头脑风暴出很多不同的方案思路，对于最新的技术我们也会互相交流学习，进行一些技术分享。

      项目组的领导对我们也有着很高的要求，比如当实现一个深度学习算法模块时，我们不仅仅是只保证算法跑出来的结果看起来没问题，而是会进行非常严谨的测试，保证其能够在多种不同的测试集上都能有效果上的提升。同时，每个月我们也会进行深刻的总结思考，追求技术上的提升

      然而，能让我们的项目最终取得了不错进展并且成功上线手淘，我觉得最重要的因素应该是：对项目良好的把握和规划。这就需要对深度学习算法有个比较全面深刻的认知，而经过在阿里工作上的锻炼，我在这方面获得了比较大的成长


3. **在英特尔学到了什么**
   
   在英特尔我就职于人工智能与数据分析团队，我所在的小组负责：人工智能应用的架构，包括 
   1)高效的数据处理 2)分布式的大模型训练 3)高性能的模型部署 4）基于GPT的问答系统搭建（RAG）
   
   1. 目前，我负责的主要内容是：为intel训练一个自己的大语言基座模型，包括**大模型的预训练，微调以及基于人类反馈的强化学习**。目前，市面上的很多模型是基于国外模型微调得到的，技术难度较低，且对中文以及个性化的内容支持较差，而国内法规要求如果要发布大模型，必须得是自己从头训练的，因此拥有对大语言模型的预训练能力非常重要的。

   我基于分布式框架Ray实现了多机多卡下的大模型预训练，结合megatron，我实现了对于模型的多维度并行（包括数据并行，流水线并行，张量并行），同时基于deepspeed，大大减少了模型训练过程中的显存开销，最终实现了高效的大语言基座模型的预训练。
   
   在此基础上，我进一步实现了：**高效的大模型微调**以及**基于人类反馈的强化学习**。微调的主要目标是让模型获得特定任务上的性能提升，例如让语言模型获得较好的对话能力。我主要实现了3种形式的微调，全参数，部分参数以及基于lora的微调，基于lora我甚至能够通过CPU实现对大语言模型的优化
   
   通过高质量的微调，可以让大模型在某一领域获得突出表现，例如可以基于人类的问题直接生成数据分析的代码，这样就可以快速分析用户的行为，方便做出市场决策。而强化学习主要是可以提升大模型的安全性，避免大模型输出反人类的回答。
   
   <!-- 以上这些对于实现高可用的大语言模型都是非常必要的，而我也完全掌握了从预训练到微调再到强化学习的一整套流程，能够切切实实帮助******实现一个自己的大模型。 -->
   
   2. 我不仅对模型的训练优化比较了解，同时对于**模型的推理优化**也比较熟悉，包括对模型的量化、剪枝与蒸馏等技术。我甚至在自家仅仅只有CPU的机器上部署了大语言模型，相对于业界动辄使用数十万元显卡进行大模型部署的方法，成本大大降低。这也是我优化了模型性能的结果
   
   3. 基于我们这一套自研的大模型训练推理框架，我研发了一套**基于文档增强的大模型应用**。在很多公司中，都会有自己的内部文档，比如内部的技术文档、员工手册、财报等等，而如果想要大语言模型基于这些文档内容进行回答，直接训练是不现实的，因为不可能每更新一些文档就训练一遍，这样成本太高。因此，我构建一套基于提问内容进行向量检索，再基于检索内容使用大模型回答的应用框架。

   我们分析了2019年至2022年上市公司的所有财报信息，构建了一个金融领域的问答大模型，完成了从数据处理、多模态数据库构建、模型微调、相关数据检索等一系列的应用模块，最终实现了对各公司财报信息的快速准确的回答。

   4. **熟悉了一套高效且国际通用的多人协作代码开发流程**，在很多国内的大公司，包括阿里、华为等等，很多都使用的事内部的开发工具，这导致到了一个新的团队后，非常不利于项目的整体把握。而我们的客户包括国内外的知名企业，比如字节、阿里、百度、微软等等，因此我们的开发流程是国内外通用且非常高效的，在英特尔的这段时间，我完全熟悉了这套流程，提升了对项目整体的把握能力
   
   5. **感受到并熟悉了大型外企的工作方式**，非常注重工作与生活的平衡，在计划的设定上非常细致，指定目标之后并不着急去实现，而是会去想好每一步的计划，列出一个月的工作细节，每周去更新进展。如果确实遇到了困难或者有价值的问题，也会给充分的时间去解决和探索。

   

4. **自身的优势是什么，为什么需要我**
   
   1. 具有顶尖互联网公司与一流外企的工作经验，可以为******带来非常有价值的人员工作安排与项目管理经验
   2. 代码开发上：
      1. 有一套高效的多人协作代码开发管理经验，能最大化团队的技术产出
      2. 熟悉人工智能算法的的一整套流程，包括数据处理、算法设计、模型训练、部署以及性能优化
      3. 亲身实践了大语言模型的全套流程，包括预训练、微调以及强化学习，能够快速帮助******构建自己的大模型应用
   3. 技术涉猎广泛，
      1. 熟悉包括：图像分割、分类、检测、3D视觉、自然语言处理等任务，
      2. 同时具有自动驾驶、互联网电商、影视游戏等行业经验
   4. 通过三年多的大公司经历，沉淀了自己的信息渠道，能获取到业内领先的算法技术进展，帮助******提前进行技术储备
   5. 基于以上条件，有能力在人工智能时代帮助******在各个行业领域进行新业务的拓展，创造产业价值


5. **在****可以做些什么？**
   1. 可以基于大语言模型实现用户数据的分析
   2. 实现******业务智能介绍的大语言模型
   3. 将******目前所拥有的算力封装成一个个垂直领域的人工智能服务，实现更大的业务增量

   4. 对于****行业自身业务的提效（ESG企业的建设）。5G的网络频率高，覆盖范围小，如何才能为用户提供高质量服务的同时降低运行成本，这就涉及到一个基本的算法思想：稀疏性。停车场中的灯只有在有人的时候才开，这时时间上的稀疏性；在没有人的荒地上不会有灯，这是空间上的稀疏性。同样，在建设成本较高的5G基站时，在人流密集的地方多建，反之则少建，这是空间上的稀疏性。时间上，当人们下班回家，商务区的基站就可以通过降低功率、减少信道数目来降低成本，即时间上的稀疏性。而这些具体的实现（怎么布局基站，何时降低基站功率），都需要依赖于算法进行解决。
   5. 对于各行各业的信息化赋能，例如自动驾驶在运行时，对时延，信息传输质量都具有极高的要求，怎么才能在已有硬件条件下更好的布局信息传输系统，降本增效，这是算法需要解决的问题。同时自动驾驶需要大量的视频数据上传，这一方面会存在数据流量的巨大需求，另一方面也需要注意保护用户隐私，做好欺诈检测和风险控制，这也是算法需要解决的事情。
   6. 对于未来重要产业的提前布局，例如通用人工智能，目前已经崭露头角的chatgpt也说明了这一点，****对此也同样可以提前布局，例如基于自身的流量优势提供数据交易平台，可以使用联邦学习技术（仅仅只共享模型参数）来实现在保护用户隐私前提条件下的数据交易，此外天翼云可以提供强大的算力支撑，同样也可以为中小企业提供算力支撑模型的训练，而作为算法工程师可以为用户提供算法优化，提升用户粘性

6. 为什么要投论文
   1. 基于实际问题有了算法上的创新（保证idea的质量）
   2. 算法的效果要严谨得通过的实验进行检验
   3. 可以和同行进行有价值的交流，宣传（为什么很多开源项目发展的好，因为大家能看到）
   4. 最优秀的算法公司都非常注重这些（OpenAI，Deepmind，国内的微软亚研院等）

7. 设计算法的一般流程（方法论）
   1. 算法描述（模糊的说：算法是干什么的，具体：输入&输出是什么）
   2. 算法边界（预见性，能否解决问题，实现难度）
   3. 算法实现（相关知识，算法框架-伪代码，数据准备，实际编写）
   4. 算法测试（多角度）

8. 算法设计思想（算法的本质是解决问题的方法，）
   1. 它山之石可以攻玉
   2. 稀疏性
   3. 空间换时间
   4. 先验信息
   5. 局部性（空间局部性，时间局部性）
   6. 对问题进行数学建模（可以使用假设简化问题）
   7. ...


核心思想是：使用寄存器实现相对于L1更高一级的缓存，减少内存的存取操作

## 项目简介

从算法

### 梯度提升决策树的加速

**项目背景**：梯度提升决策树（GBDT）是结合了决策树以及 boosting 的一类算法，它的应用非常广泛，包括推荐系统，诈骗检测等，这些场景对实时性都有很高的要求，因此算法性能的提升是非常重要的。目前已有的加速方案，都只是在数据维度上进行并行，而我从多个维度进行了并行。

**技术创新**：

1. 传统决策树的预测流程是每个节点做一个判断，这个过程存在非常多的分支预测，如果预测错误，会导致cpu的流水线进行回退刷新，大大降低运行速度

2. 基于这个假设，我想到将多层的树结构进行合并，通过向量化的一次性计算，可以直接得到3/4层的预测结果。具体实现方式就是：blabla。通过这种方式，我们压缩了树的深度，大大减少了分支预测的操作。（核心实现采用c++）

3. 实现这个group的过程其实遇到了很多的问题：
   1. 使用了group之后，tree的结构怎么设计
   2. 如何尽可能跨越更多的层
   3. lookup table怎么生成
   4. 考察算法的bottleneck

4. 发现算法时间消耗集中在内存访问，我也设计了很多解决方案（对数据预先重排，）最终通过分析汇编代码，想到可以直接使用寄存器作为高速缓存，直接避免内存的访问

5. 为了实现这个目的，我设计了基于group的sharing方案，并建立了一个简单的数学模型去提升group的共享率。具体方法：blabla。最终，在之前的基础上进一步提升了速度

### 鲁棒的神经网络重建

**项目背景**： 随着手淘 3D 化的发展，“低成本、高质量的 3D 建模”成为主要的制约因素，
而传统重建技术（SFM）较易受到 mesh 表征（三角面片）的精度限制且鲁棒性差，难以应用于实际业务中

1. 3D 模型表征： 提出了粗模 + 神经网络的 3D 模型表征形式。神经网络提供高质量的 2D 出图效果，粗模保证
神经网络模型的可扩展性，解决了神经网络隐式模型与传统 mesh 模型的组合问题

2. 多视角鲁棒：基于 NeRF 的视角合成极易过拟合，当测试视角与训练视角差异较大时，效果较差。提出了视
角鲁棒的 RapNeRF 方案（Ray Priors through Reprojection）：
   1. 基于随机视线进行数据增强 
   2. 利用视角先验信息进行推理
   3. PSNR(↑ 4.)/SSIM/LPIPS 相较于 SOTA 均获得较大提升（CVPR 2022 ACCEPTED，一作）

3. 重建链路开发： 链路核心开发者（70% commit），完成第一版的链路各模块搭建（包括位姿估计，图像分
割，物体重建，2D 图像合成等）及后续版本的迭代优化


### 3D神经网络模型的手淘端上应用（AdaSRG）

**项目背景**：

1. 传统 MLP 的网络结构（NeRF）无法表征物体的高频纹理细节（如布料纹理等），而业务应用对
物体细节要求较高（需 1 比 1 还原） 

2. 端上推理对模型大小要求较高（5MB 以内），保证材质、光照效果

**算法细节**

（想要将图像级别的loss用于3D，提高模型精度）

1. 纹理细节还原： 提出了基于 image level loss（感知损失）的体素化重建方案，大大提升了纹理细节效果，
SSIM/LPIPS 指标均达到 SOTA

2. 体素模型压缩：传统体素化重建方案（PlenOctree/SNeRG）模型大小为 GB 级别，无法满足端上应用的需求。
提出 Adaptive Sparse Radiance Grid (AdaSRG) 方案，
   1. 在纹理细节的高频区域使用较高体素粒度，低频区域使用较低体素粒度 
   2. 对 𝜎（物质密度）进行正则，去除随机噪声 
   3. 基于 PNG 算法对体素纹理进行压缩

2. 模型光照还原： 1. 采用 Deferred Light 结构解耦重建模型的 specular&diffuse color，保证光照效果 2. 编写基
于 CUDA 的实时可视化渲染程序

3. 业务应用： 重建的小物体模型成功上线手淘，实现了算法、工程至应用的打通

