---
title: "Text2SQL 大模型微调实战"
date: "2026-01-28"
tags: ["LLM", "Fine-tuning", "LoRA", "Text2SQL"]
draft: false
summary: "分享基于 LoRA 微调 Qwen-7B 实现自然语言转 SQL 的完整流程，准确率达到 98.56%。"
authors: ["default"]
---

## 项目背景

在企业数据分析场景中，非技术人员往往需要通过 SQL 查询数据库。Text2SQL 技术可以让用户用自然语言描述需求，自动生成对应的 SQL 语句。

## 技术方案

### 模型选择

选择 Qwen-7B 作为基础模型，原因：

- 中文理解能力强
- 参数量适中，可在单卡 A100 上微调
- 社区活跃，资料丰富

### LoRA 微调

使用 LoRA (Low-Rank Adaptation) 进行高效微调：

```python
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

model = get_peft_model(base_model, lora_config)
```

### 数据集构建

基于 Spider 和 WikiSQL 数据集，构建了 10 万条中英文混合样本：

| 数据集   | 样本数 | 表数量 |
| -------- | ------ | ------ |
| Spider   | 7000   | 200    |
| WikiSQL  | 80000  | 26000  |
| 自建数据 | 13000  | 150    |

## 实验结果

在测试集上的准确率：

- **执行准确率**: 98.56%
- **精确匹配率**: 87.3%
- **推理速度**: 50ms/query

## 总结

通过 LoRA 微调可以在有限资源下获得优秀效果。下一步计划探索多轮对话场景下的 SQL 生成。
